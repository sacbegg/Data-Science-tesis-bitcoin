---
title: "Selección de modelo para predicción"
output:
  html_notebook: default
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

## Librerías

La librería xts nos ayuda a formatear un archivo csv a un formato de serie de tiempo

```{r}
library(xts)
library(fpp2)
library(tictoc)
library(forecast)
library(kernlab)
library(ranger)
library(DescTools)
library(keras)
library(tensorflow)
```

## Carga y procesamiento de datos

```{r}
# Carga de archivo csv en formato OHLCV del precio
btc_median <- read.zoo('/Users/sacbe/Documents/Tesis licenciatura/Algoritmos/cleaning/BTC-USD.csv', sep = ",", header =TRUE)
btc_median <- as.xts(btc_median)
index(btc_median) <- as.Date(index(btc_median))
btc_median <- btc_median['/2022-04-14']

head(btc_median)

# Carga de archivo CSV con metricas de la blockchain
btc_blockchain <- read.zoo('/Users/sacbe/Documents/Tesis licenciatura/Algoritmos/cleaning/BTC-coinMetrics.csv', sep = ",", header =TRUE)
btc_blockchain <- as.xts(btc_blockchain)
index(btc_blockchain) <- as.Date(index(btc_blockchain))
btc_blockchain <- subset(btc_blockchain, select = -PriceUSD)
btc_blockchain <- btc_blockchain['/2022-04-14']

# Creación de dataframe con metricas financieras y de la blockchain
btc_median_cmetric <- merge(x = btc_median, y = btc_blockchain, join = 'inner')

if (sum(is.na(btc_median_cmetric)) > 0){
  print("Hay valores faltantes")
}

# Remplazo de ceros para evitar errores de calculo

btc_median_cmetric[btc_median_cmetric == 0] = 0.1
```

```{r}
library(ggcorrplot)
ggcorrplot(cor(btc_median))
```

```{r}
head(btc_median_cmetric)
write.csv(btc_median_cmetric,"/Users/sacbe/Documents/Tesis licenciatura/Algoritmos/cleaning/BTC_median_cmetric.csv")
```

## Visualización de los datos

```{r}
print(BoxCox.lambda(btc_median_cmetric$Close))

diff_price <- diff(btc_median_cmetric$Close)

btc_plot <- ggplot(btc_median_cmetric, aes(index(btc_median_cmetric) , Close)) +
  geom_line(data = btc_median_cmetric, color = "black") +
  theme_minimal() +
  #labs(title = "Bitcoin precio de cierre en dólares", x = " ", y = "")+
  ggtitle("Bitcoin precio de cierre en dólares")+
  labs(x = "Años", y="Precio en dólares")+
  theme(text = element_text(family = "LM Roman 10"))

btc_plot
```

## Creación de conjunto de prueba y entrenamiento

```{r}
s <- as.integer(nrow(btc_median_cmetric)*0.8)
train <- btc_median_cmetric[1:s,]
test <- btc_median_cmetric[(s+1):nrow(btc_median_cmetric),]
```

## Definición variables para comparación de medidas de error

Se definen listas para guardar los resultados de predicción de los modelos y se guardan las métricas de error en matrices para comparación de modelos.

```{r}
models_names <- c('Naive', 'SES', 'Holt','ETS','ARIMA', 'Regresion', 'SVM','RF',"LSTM")
transform_names <- c('Original', 'log', 'BoxCox', 'diff', 'diff(log)') 
RMSE <- matrix(nrow = length(models_names), ncol = length(transform_names))
RMSE_test <- matrix(nrow = length(models_names), ncol = length(transform_names))
colnames(RMSE) <- transform_names
rownames(RMSE) <- models_names
colnames(RMSE_test) <- transform_names
rownames(RMSE_test) <- models_names

ACC <- matrix(nrow = length(models_names), ncol = length(transform_names))
ACC_test <- matrix(nrow = length(models_names), ncol = length(transform_names))
colnames(ACC) <- transform_names
rownames(ACC) <- models_names
colnames(ACC_test) <- transform_names
rownames(ACC_test) <- models_names

naive_list <- list()
ses_list <- list()
holt_list <- list()
ets_list <- list()
arima_list <- list()
regresion_list <- list()
svm_list <- list()
rf_list <- list()
lstm_list <- list()
```

## Definición de funciones

Se definen funciones para operar sobre los datos de dataframe.

```{r}
rmse <- function(error){
  sqrt(mean(error^2))
}
lags <- function(x, k){
  
  lagged =  c(rep(NA, k), x[1:(length(x)-k)])
  DF = as.data.frame(cbind(lagged, x))
  colnames(DF) <- c( paste0('x-', k), 'x')
  DF[is.na(DF)] <- 0
  return(DF)
}
normalize = function(train, test, feature_range = c(0, 1)) {
  #Normalizamos los datos con el maximo de los datos de entrenamiento
  x = train
  fr_min = feature_range[1]
  fr_max = feature_range[2]
  std_train = ((train - min(x) ) / (max(x) - min(x)  ))
  std_test  = ((test - min(x) ) / (max(x) - min(x)  ))
  
  scaled_train = std_train *(fr_max -fr_min) + fr_min
  scaled_test = std_test *(fr_max -fr_min) + fr_min
  
  return(list(scaled_train = as.vector(scaled_train), 
              scaled_test = as.vector(scaled_test),
              scaler= c(min =min(x), max = max(x))))
}

normalize_z = function(data, feature_range = c(0, 1), scaled = 1) {
  #Normalizamos los datos con el maximo del dataframe
  x = data
  fr_min = feature_range[1]
  fr_max = feature_range[2]
  std_data = ((x - min(x)) / (max(x) - min(x)))
  
  scaled_data = std_data *(fr_max -fr_min) + fr_min
  
  if(scaled == 1){
    return(list(scaled_data = as.vector(scaled_data),
              scaler= c(min(x),max(x))))
  }
  else return(scaled_data = as.vector(scaled_data))
  
}

inverter = function(scaled, scaler, feature_range = c(0, 1)){
  min = scaler[1]
  max = scaler[2]
  n = length(scaled)
  mins = feature_range[1]
  maxs = feature_range[2]
  inverted_dfs = numeric(n)
  
  for(i in 1:n){
    X = (scaled[i]- mins)/(maxs - mins)
    rawValues = X *(max - min) + min
    inverted_dfs[i] <- rawValues
  }
  return(inverted_dfs)
}
```

## Entrenamiento con modelos estadísticos univariados

```{r}
time_pred <- length(test$Close)
tic()
for (i in 1:5) {
  if(i == 1){
    t_trainData <- train$Close
  } else if(i == 2){
    t_trainData <- log(train$Close)
  } else if(i == 3){
    t_trainData <- BoxCox(train$Close, lambda = BoxCox.lambda(train$Close))
  } else if(i == 4){
    t_trainData <- na.fill(diff(train$Close),"extend")
  } else{
    t_trainData <- na.fill(diff(log(train$Close)),"extend")
  }
  #Naive
  naive.btc <- naive(t_trainData, h=time_pred)
  #SES
  ses.btc <- ses(t_trainData, h=time_pred)
  #Holt
  h.btc <- holt(t_trainData, h=time_pred, damped = TRUE)
  #ETS
  ets.btc <- ets(as.ts(t_trainData))
  etsf.btc <- forecast(ets.btc, time_pred)

  #ARIMA
  arima.btc <- auto.arima(as.ts(t_trainData))
  arimaf.btc <- forecast(arima.btc, time_pred)
  
  if(i == 1){ # Predicción sobre datos sin transformar
    naive.btc$fitted = na.fill(naive.btc$fitted,"extend")
    ses.btc$fitted = ses.btc$fitted
    h.btc$fitted = h.btc$fitted
    etsf.btc$fitted = etsf.btc$fitted
    arimaf.btc$fitted = arimaf.btc$fitted
  }else if(i == 2){ # Predicción sobre datos con transformación log
    naive.btc$fitted = na.fill(exp(naive.btc$fitted),"extend")
    ses.btc$fitted = exp(ses.btc$fitted)
    h.btc$fitted = exp(h.btc$fitted)
    etsf.btc$fitted = exp(etsf.btc$fitted)
    arimaf.btc$fitted = exp(arimaf.btc$fitted)
  }else if(i == 3){ # Predicción sobre datos con transformación BoxCox
    naive.btc$fitted = na.fill(InvBoxCox(naive.btc$fitted, lambda = BoxCox.lambda(train$Close)),"extend")
    ses.btc$fitted = InvBoxCox(ses.btc$fitted, lambda = BoxCox.lambda(train$Close))
    h.btc$fitted = InvBoxCox(h.btc$fitted, lambda = BoxCox.lambda(train$Close))
    etsf.btc$fitted = InvBoxCox(etsf.btc$fitted, lambda = BoxCox.lambda(train$Close))
    arimaf.btc$fitted = InvBoxCox(arimaf.btc$fitted, lambda = BoxCox.lambda(train$Close))
  }else{
    #i <- 4
    for (j in 1:(length(train$Close))) {
      
      if(i == 4){ # Predicción sobre datos con transformación diff
        naive.btc$fitted[j]  =  naive.btc$fitted[j] + btc_median_cmetric$Close[(1+j)]
        ses.btc$fitted[j]  = ses.btc$fitted[j] + btc_median_cmetric$Close[(1+j)]
        h.btc$fitted[j]  = h.btc$fitted[j] + btc_median_cmetric$Close[(1+j)]
        etsf.btc$fitted[j]  = etsf.btc$fitted[j] + btc_median_cmetric$Close[(1+j)]
        arimaf.btc$fitted[j]  = arimaf.btc$fitted[j] + btc_median_cmetric$Close[(1+j)]
        
      }else{ # Predicción sobre datos con transformación diff(log)
        naive.btc$fitted[j]  = exp(naive.btc$fitted[j]) + btc_median_cmetric$Close[(1+j)]
        ses.btc$fitted[j]  = exp(ses.btc$fitted[j]) + btc_median_cmetric$Close[(1+j)]
        h.btc$fitted[j]  = exp(h.btc$fitted[j]) + btc_median_cmetric$Close[(1+j)]
        etsf.btc$fitted[j]  = exp(etsf.btc$fitted[j]) + btc_median_cmetric$Close[(1+j)]
        arimaf.btc$fitted[j]  = exp(arimaf.btc$fitted[j]) + btc_median_cmetric$Close[(1+j)]
      }
    }
    
  }
  if(i == 4 | i == 5){ # Se eliminan NaNs en transformaciones diff
    naive.btc$fitted = na.fill(naive.btc$fitted,"extend")
  }
  # Guardado de predicciones y calculo de indicadores de error
  naive_list[[i]] <- naive.btc$fitted
  RMSE[1,i] <- rmse(train$Close - as.vector(naive_list[[i]]))
  ACC[1,i] <- TheilU(train$Close, as.vector(naive_list[[i]]))
  ses_list[[i]] <- ses.btc$fitted
  RMSE[2,i] <- rmse(train$Close - as.vector(ses_list[[i]]))
  ACC[2,i] <- TheilU(train$Close, as.vector(ses_list[[i]]))
  holt_list[[i]] <- h.btc$fitted
  RMSE[3,i] <- rmse(train$Close - as.vector(holt_list[[i]]))
  ACC[3,i] <- TheilU(train$Close, as.vector(holt_list[[i]]))
  ets_list[[i]] <- etsf.btc$fitted
  RMSE[4,i] <- rmse(train$Close - as.vector(ets_list[[i]]))
  ACC[4,i] <- TheilU(train$Close, as.vector(ets_list[[i]]))
  arima_list[[i]] <- arimaf.btc$fitted  
  RMSE[5,i] <- rmse(train$Close - as.vector(arima_list[[i]]))
  ACC[5,i] <- TheilU(train$Close, as.vector(arima_list[[i]]))
  train$Close <- train$Close
}
toc()
```

## Entrenamiento con modelos de machine learning

```{r}
tic()
for (i in 1:5) {
  t_trainData <- train
  if(i == 1){
    t_trainData <- t_trainData
  } else if(i == 2){
    t_trainData <- log(t_trainData)
  } else if(i == 3){
    lambda = BoxCox.lambda(train$Close)
    t_trainData <- as.data.frame(lapply(t_trainData[ ,1:ncol(t_trainData)], BoxCox, lambda = lambda))
  } else if(i == 4){
    t_trainData <- na.spline(diff(t_trainData))
  } else{
    t_trainData <- na.spline(diff(log(t_trainData)))
  }
  # Eliminar posibles columnas no necesarias en escalado de datos
  col = names(t_trainData)[names(t_trainData) != c(" ")]

  Scaled <- as.data.frame(lapply(t_trainData[,col], normalize_z, scaled = 0))
  
  scaler = normalize_z(t_trainData$Close)$scaler
  t_trainData = as.ts(Scaled)
  
  head(t_trainData)
  # Regresión sobre series de tiempo
  regresion.btc <- tslm(Close ~ Open + High + Low + Volume_Currency + HashRate + AdrBalUSD1MCnt, data = t_trainData, lambda = NULL)
  regresionf.btc <- predict(regresion.btc,as.data.frame(t_trainData))
  
  # Maquinas de vectores de soporte
  invisible(capture.output(svm.btc <- ksvm(Close ~ Open + High + Low + Volume_Currency + HashRate + AdrBalUSD1MCnt, data = as.data.frame(t_trainData), kernel = "vanilladot")))
  svmf.btc <- predict(svm.btc,as.data.frame(t_trainData))
  
  # Arboles aleatorios
  rf.btc <- ranger(Close ~ Open + High + Low + Volume_Currency + HashRate + AdrBalUSD1MCnt, data = as.data.frame(t_trainData), num.trees = 500, seed = 123)
  rff.btc <- predict(rf.btc,as.data.frame(t_trainData))$predictions
  
  # Se invierte el escaldo
  regresionf.btc = inverter(regresionf.btc,scaler)
  svmf.btc = inverter(svmf.btc,scaler)
  rff.btc = inverter(rff.btc,scaler)
  
  if(i == 1){
    svmf.btc = svmf.btc
    rff.btc = rff.btc
    regresionf.btc = regresionf.btc
  }else if(i == 2){
    svmf.btc = exp(svmf.btc)
    rff.btc = exp(rff.btc)
    regresionf.btc = exp(regresionf.btc)
  }else if(i == 3){
    svmf.btc = InvBoxCox(svmf.btc, lambda = BoxCox.lambda(train$Close))
    rff.btc = InvBoxCox(rff.btc, lambda = BoxCox.lambda(train$Close))
    regresionf.btc = InvBoxCox(regresionf.btc, lambda = BoxCox.lambda(train$Close)) 
  }else{
    for (j in 1:length(train$Close)) {
      if(i == 4){
        svmf.btc[j]  = svmf.btc[j] + btc_median_cmetric$Close[(1+j)]
        rff.btc[j]  = rff.btc[j] + btc_median_cmetric$Close[(1+j)]
        regresionf.btc[j]  = regresionf.btc[j] + btc_median_cmetric$Close[(1+j)]
      }else{
        svmf.btc[j]  = exp(svmf.btc[j]) + btc_median_cmetric$Close[(1+j)]
        rff.btc[j]  = exp(rff.btc[j]) + btc_median_cmetric$Close[(1+j)]
        regresionf.btc[j]  = exp(regresionf.btc[j]) + btc_median_cmetric$Close[(1+j)]
      }
    }
  }
  
  # Guardado de predicciones y calculo de indicadores de error
  regresion_list[[i]] <- regresionf.btc
  RMSE[6,i] <- rmse(na.approx(train$Close - regresionf.btc))
  ACC[6,i] <- TheilU(train$Close, regresionf.btc, na.rm = TRUE)
  svm_list[[i]] <- svmf.btc
  RMSE[7,i] <- rmse(na.approx(train$Close - svmf.btc))
  ACC[7,i] <- TheilU(train$Close, svmf.btc, na.rm = TRUE)
  length(svmf.btc)
  length(rff.btc)
  rf_list[[i]] <- rff.btc
  RMSE[8,i] <- rmse(na.approx(train$Close - rff.btc))
  ACC[8,i] <- TheilU(train$Close, rff.btc,na.rm = TRUE)

}
toc()
```

## Entrenamiento con LSTM

```{r}
tic()
for (i in 1:5) {
  if(i == 1){
    transf = btc_median_cmetric$Close
  }else if(i == 2){
    transf = log(btc_median_cmetric$Close)
  }else if(i == 3){
    transf = BoxCox(btc_median_cmetric$Close, lambda = BoxCox.lambda(btc_median_cmetric$Close))
  }else if(i == 4){
    transf = diff(btc_median_cmetric$Close, differences = 1)
  }else{
    transf = diff(log(btc_median_cmetric$Close), differences = 1)
  }
  supervised = lags(transf, 1)
  supervised_scaled <- as.data.frame(lapply(supervised[1:2], normalize_z,feature_range = c(-1, 1)))
  
  train_lstm = supervised_scaled[1:s, ]
  test_lstm  = supervised_scaled[(s+1):nrow(btc_median_cmetric), ]

  y_train = train_lstm[, 2]
  x_train = train_lstm[, 1]
  y_test = test_lstm[, 2]
  x_test = test_lstm[, 1]

  # Reshape the input to 3-dim
  dim(x_train) <- c(length(x_train), 1, 1)
  
  # specify required arguments
  X_shape2 = dim(x_train)[2]
  X_shape3 = dim(x_train)[3]
  batch_size = 1
  units = 1
  
  model <- NULL
  model <- keras_model_sequential() 
  model%>%
    layer_lstm(units, batch_input_shape = c(batch_size, X_shape2, X_shape3), stateful= TRUE)%>%
    layer_dense(units = 1)
  
  model %>% compile(
    loss = 'mean_squared_error',
    optimizer = optimizer_adam( learning_rate= 0.01 , decay = 1e-6 ),  
    metrics = c('accuracy')
  )

  #summary(model)
  
  nb_epoch = 10
  for(j in 1:nb_epoch ){
    cat("Modelo:",i,", Epoch:",j,"\n")
    model %>% fit(x_train, y_train, epochs=1, batch_size=batch_size, verbose=1, shuffle=FALSE)
    model %>% reset_states()
  }
  
  L = length(x_train)
  scaler = supervised_scaled$x.scaler[1:2]
  predictions = numeric(L)
  lambda = BoxCox.lambda(btc_median_cmetric$Close)
  for(k in 1:L){
    X = x_train[k,,]
    dim(X) = c(1,1,1)
    # Predicción
    yhat = model %>% predict(X, batch_size=batch_size)
    # Invertir escala
    yhat = inverter(yhat, scaler,  c(-1, 1))
    # Invertir transformaciones
    if(i==1){
      yhat = yhat
    }else if(i==2){
      yhat = exp(yhat)
    }else if(i==3){
      yhat = InvBoxCox(yhat, lambda = lambda) 
    }else if(i==4){
      yhat  = yhat + btc_median_cmetric$Close[(1+k)]  
    }else{
      yhat  = exp(yhat) + btc_median_cmetric$Close[(1+k)]
    }
    # Guardar predicción
    predictions[k] <- yhat
  }
  lstm_list[[i]] <- predictions
  RMSE[9,i] <- rmse(train$Close - lstm_list[[i]])
  ACC[9,i] <- TheilU(train$Close, lstm_list[[i]])
}
toc()
```

## Elección de mejor modelo

```{r}
min <- apply( RMSE, 2, which.min)
best_model <-rownames(RMSE[min,])
bestRMSE <- data.frame('Transformation' = transform_names,'Best.model.RMSE' = best_model)
min <- apply( ACC, 2, which.min)
best_model <-rownames(ACC[min,])
bestACC <- data.frame('Transformation' = transform_names,'Best.model.RMSE' = best_model)
RMSE
ACC
#bestRMSE
#bestACC

inx <- which(RMSE == min(RMSE), arr.ind = TRUE)
iny <- which(ACC == min(ACC), arr.ind = TRUE)

bestModel <- data.frame("Best RMSE"=RMSE[inx],"Best Theils U" = ACC[iny]) 
bestModel <- cbind("Modelo" = models_names[inx[1]], bestModel)
bestModel
```

## Gráfica modelo seleccionado

```{r}
t_trainData <- train
t_testData <- test
t_trainData <- log(t_trainData)
t_testData <- log(t_testData)

col_train = names(t_trainData)[names(t_trainData) != c(" ")]
col_test = names(t_testData)[names(t_trainData) != c(" ")]
Scaled_train <- as.data.frame(lapply(t_trainData[,col], normalize_z, scaled = 0))
Scaled_test <- as.data.frame(lapply(t_testData[,col], normalize_z, scaled = 0))
  
scaler_train = normalize_z(t_trainData$Close)$scaler
t_trainData = as.ts(Scaled_train)
scaler_test = normalize_z(t_testData$Close)$scaler
t_testData = as.ts(Scaled_test)

rf.btc <- ranger(Close ~ Open + High + Low + Volume_Currency + HashRate + AdrBalUSD1MCnt, data = as.data.frame(t_trainData), num.trees = 500, seed = 123)
rff.btc <- predict(rf.btc,as.data.frame(t_testData))$predictions
rff.btc = inverter(rff.btc,scaler_test)
#rff.btc = InvBoxCox(rff.btc, lambda = BoxCox.lambda(test$Close))
rff.btc = exp(rff.btc)
```

```{r}
rff.btc.df = as.data.frame(rff.btc)
colnames(rff.btc.df) <- "Close"

ggplot(data=test$Close, aes(index(test$Close),Close)) +
  geom_point(data = test$Close, aes(colour = "Original"))+
  geom_line(data = rff.btc.df, aes(colour = "Predicción"))+
  labs(title = "Random Forest", y = "Precio en dólares", x = "Fecha")+
  theme_minimal()+
  theme(text = element_text(family = "LM Roman 10"))+
  scale_colour_manual(name=" ",
      values=c(Original="black", Predicción="red"))+
  theme(legend.position = "bottom")

cat("RMSE: ",rmse(na.approx(test$Close - rff.btc)))
cat("Theil's U: ",TheilU(test$Close, rff.btc))

```

```{r}
t_trainData <- train
t_testData <- test
t_trainData <- log(t_trainData)
t_testData <- log(t_testData)

col_train = names(t_trainData)[names(t_trainData) != c(" ")]
col_test = names(t_testData)[names(t_trainData) != c(" ")]
Scaled_train <- as.data.frame(lapply(t_trainData[,col], normalize_z, scaled = 0))
Scaled_test <- as.data.frame(lapply(t_testData[,col], normalize_z, scaled = 0))
  
scaler_train = normalize_z(t_trainData$Close)$scaler
t_trainData = as.ts(Scaled_train)
scaler_test = normalize_z(t_testData$Close)$scaler
t_testData = as.ts(Scaled_test)

rf.btc <- ranger(Close ~ Open + High + Low + Volume_Currency, data = as.data.frame(t_trainData), num.trees = 500, seed = 123)
rff.btc <- predict(rf.btc,as.data.frame(t_trainData))$predictions
rff.btc = inverter(rff.btc,scaler_train)
#rff.btc = InvBoxCox(rff.btc, lambda = BoxCox.lambda(test$Close))
rff.btc = exp(rff.btc)

rff.btc.df = as.data.frame(rff.btc)
colnames(rff.btc.df) <- "Close"

ggplot(data=train$Close, aes(index(train$Close),Close)) +
  geom_point(data = train$Close, aes(colour = "Original"))+
  geom_line(data = rff.btc.df, aes(colour = "Predicción"))+
  labs(title = "Random Forest", x = " ", y = " ")+
  theme_minimal()+
  theme(text = element_text(family = "LM Roman 10"))+
  scale_colour_manual(name=" ",
      values=c(Original="black", Predicción="red"))+
  theme(legend.position = "bottom")

cat("RMSE: ",rmse(na.approx(train$Close - rff.btc)))
cat("Theil's U: ",TheilU(train$Close, rff.btc))
```
```{r}
RMSE
ACC
```

